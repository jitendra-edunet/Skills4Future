{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab : Fine-Tuning Pre-trained Models for Climate Change Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "The increasing frequency of wildfires has made it essential to develop accurate prediction models that can quickly identify fire-prone areas. This lab focuses on creating a wildfire detection model using satellite images. We fine-tune a pre-trained MobileNet model to classify satellite images into \"Fire\" and \"No Fire\" categories, which can contribute to early wildfire detection and prevention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Objective\n",
    "- To utilize transfer learning by fine-tuning the pre-trained MobileNet model for binary classification (Fire vs. No Fire).\n",
    "- To preprocess and train the model using satellite images from the \"Wildfire Prediction Dataset.\"\n",
    "- To evaluate the model’s performance in identifying wildfire-prone areas based on satellite images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Requirements\n",
    "\n",
    "**To Train the model in Local System**\n",
    "\n",
    "**Hardware:**\n",
    "- GPU (Recommended for faster training, e.g., Nvidia CUDA-compatible GPUs)\n",
    "- RAM: 8 GB or more\n",
    "- Storage: At least 5 GB of free space for datasets and model storage\n",
    "\n",
    "**Software:**\n",
    "- Python 3.x\n",
    "- TensorFlow 2.x\n",
    "- Pandas, NumPy\n",
    "- Matplotlib (Optional for visualization)\n",
    "- Jupyter Notebook or any Python IDE\n",
    "- GPU drivers and CUDA (if available)\n",
    "\n",
    "It is recommended to use google colab, so there will not be any need of setting up the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "- Name: Wildfire Prediction Dataset\n",
    "- Description: This dataset contains satellite images classified as either \"Fire\" or \"No Fire.\" It is designed for training and testing models for wildfire prediction.\n",
    "- Source: Kaggle: Wildfire Prediction Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Download**<br>\n",
    "The dataset is downloaded from Kaggle using the Kaggle API, which requires an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: download the kaggle dataset here:\n",
    "# https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset\n",
    "!pip install kaggle\n",
    "\n",
    "# Upload your Kaggle API key (kaggle.json)\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "# Move the API key to the correct location\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the dataset\n",
    "!kaggle datasets download -d abdelghaniaaba/wildfire-prediction-dataset\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip wildfire-prediction-dataset.zip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section installs the Kaggle library and uses an uploaded Kaggle API key to access and download the dataset. It then unzips the dataset, making it available for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries and Setting Parameters**<br>\n",
    "The essential libraries and parameters for the model are loaded and initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Parameters\n",
    "input_shape = (224, 224, 3)  # Standard input size for MobileNet\n",
    "num_classes = 2  # Fire or No Fire\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the input shape to 224x224 pixels, the required input for MobileNet. The batch size, learning rate, and the number of training epochs are also defined.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing and Augmentation**<br>\n",
    "Image data is preprocessed, and augmentation techniques are applied to improve model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'valid',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ImageDataGenerator class is used for rescaling and augmenting images. Augmentation techniques include rotation, width/height shifting, and flipping, helping to diversify the training dataset and reduce overfitting. The dataset is split into training and validation subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Pre-trained MobileNet Model**<br>\n",
    "We load the MobileNet model with pre-trained weights from ImageNet and freeze the layers to retain existing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the base model layers to prevent training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet is loaded without the top layer, as we’ll add a custom top layer for binary classification. Freezing layers ensures the pre-trained weights aren’t modified during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Model Architecture**<br>\n",
    "The custom top layers are added to the MobileNet base to adapt it for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(128, activation='relu'),  # Optional fully connected layer\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (fire or no fire)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A global average pooling layer is added to reduce the spatial dimensions, followed by a dense layer with ReLU activation to introduce non-linearity. The final layer uses a sigmoid activation function for binary classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**<br>\n",
    "The model is compiled with the Adam optimizer and binary cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adam optimizer is selected for adaptive learning rate capabilities, and binary cross-entropy is used as the loss function, appropriate for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**<br>\n",
    "The model is trained on the training data with validation after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function trains the model on the training data while validating on a separate set to track performance. Training for multiple epochs helps optimize the model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation and Saving**<br>\n",
    "Evaluate the model’s performance and save the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "model.save('forest_fire_detection_mobilenet.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is evaluated on validation data, providing an accuracy metric to gauge its performance. The trained model is then saved in .h5 format, making it available for deployment or further fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
